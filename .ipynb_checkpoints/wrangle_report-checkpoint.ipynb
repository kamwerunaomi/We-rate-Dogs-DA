{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRANGLE REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gathered the WeRateDogs data by reading from a csv file and from the twitter API and reaidng it into a JSON file.\n",
    "After assessing the data both visually and programmatically, I noted that the data had several quality and tidiness issues which included:\n",
    "Wrong data type for timestampand retweeted_status_timestamp.\n",
    "\n",
    "1. Rating denominator does not equal 10\n",
    "\n",
    "2. Dogs without names given 'a' instead on None\n",
    "\n",
    "3. Redundant rows in in_reply.. rows\n",
    "\n",
    "4. Redundant rows in retweeted rows\n",
    "\n",
    "5. Wrong ratings for some tweets\n",
    "\n",
    "6. Some rows have 3 false predictions which might not be accurate\n",
    "\n",
    "7. Wrong data type for tweet_id in retweet_count_and_favorite_count dataframe\n",
    "\n",
    "8. There are some redundant rows of the same category that is doggo,floofer,pupper and puppo\n",
    "\n",
    "9. The retweet_count and favorite_count should be part of the twitter_archive dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "#### Quality Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then took the following steps in cleaning the data.\n",
    "First, I made copies of the data for backup incase I needed to go back to the original.\n",
    "I then went ahead to correct the data type issues where I changed the timestamps data type to datetime.\n",
    "\n",
    "`twitter_clean['timestamp'] = pd.to_datetime(twitter_clean['timestamp'])\n",
    "twitter_clean['retweeted_status_timestamp'] = pd.to_datetime(twitter_clean['retweeted_status_timestamp'])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After every code, it was important for me to test, to confirm that the changes have taken place.\n",
    "I went ahead to drop all the rows that had a denominator that was not equal to 10 using:\n",
    "\n",
    "`not_ten=list(twitter_clean.query('rating_denominator != 10').index)\n",
    "twitter_clean.drop(index=not_ten, inplace=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next was to correct the dog names that were given an or a and replace that with None by adding the wrong dog names to a list and then checking if the items in the list appear in the names column and replacing then with None.\n",
    "\n",
    "`wrong_dog_names = list(twitter_clean.query('name==\"a\" or name==\"an\"').index)\n",
    "for i in wrong_dog_names:\n",
    "    twitter_clean.name[i] = \"None\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next was to drop the redundant rows in the in reply rows and the retweeted rows. This was done by first dropping them in the axis 0 and then in the axis 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I corrected the tweets that had wrong ratings of more than 100 by dropping those columns.\n",
    "Next was to drop the rows that had 3 false predictions since they were not accurate predictions, it was best if they were dropped.\n",
    "\n",
    "`false_pred = list(image_pred_clean.query('p1_dog==\"False\" and p2_dog==\"False\" and p3_dog==\"False\"').index)\n",
    "image_pred_clean.drop(axis=0, index=false_pred, inplace=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some redundant columns that is doggo, floofer, pupper and puppo. All these columns are the dog stages. I corrected this by merging these columns into one and named it Stage and then dropped the others.\n",
    "\n",
    "`twitter_clean['Stage'] = twitter_clean.doggo +  twitter_clean.floofer +twitter_clean.pupper +twitter_clean.puppo\n",
    "twitter_clean['Stage'] = twitter_clean['Stage'].map(lambda x: x.replace(\"None\",\"\"))\n",
    "twitter_clean.drop(['doggo','floofer','pupper','puppo'], axis=1, inplace=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the retweet and favorite count would make more sense if they were part of the twitter_archive dataframe. I corrected this by merging those columns to the table on the tweet_id.\n",
    "\n",
    "`twitter_clean = pd.merge(twitter_clean, retweet_favorite_clean, on=['tweet_id'], how='left')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then stored the cleaned data to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
